model:
  name: "TinyLlama/TinyLlama-1.1B-Chat-v1.0" # Smaller model
  adapter: "lora"
  load_path: "models/base" 
  save_path: "../models/weights.pth" 
data:
  path: "../dist/data/dataset.jsonl"
  max_samples: 500
  val_split: 0.1
train:
  epochs: 1000
  batch_size: 1 # Reduced for CPU/Monitoring
  max_seq_len: 256 # Reduced for speed/memory
  lr: 5.0e-5
  weight_decay: 0.0
  warmup_steps: 50
  grad_clip: 1.0
  log_every: 1
  save_every: 100
runtime:
  device: "cuda"
  workers: 4
